{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d000d9f-ab4b-425a-85d4-762348dcf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "tokenized_datasets = datasets.load_from_disk('../4_str_to_token/tokenized_datasets')\n",
    "print(tokenized_datasets)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" #tokenizerの警告を消す\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #DataCollatorForLanguageModelingの警告を減らす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffad58f-49c4-43e7-8f35-9d9c1c0b9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaConfig, LlamaForCausalLM\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "my_model_type=\"llama_60m\"\n",
    "config = LlamaConfig.from_json_file(f\"configs/{my_model_type}.json\")\n",
    "model = LlamaForCausalLM(config)\n",
    "\n",
    "spm_folder = \"../3_make_tokenizer/sentencepiece/\"\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file = spm_folder + \"spm_tokenizer.json\",\n",
    ")\n",
    "print(tokenizer.encode(\"[NL]\"),tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b31845-d8e0-4f68-81db-0f5428bb82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = model.to(dtype=torch.bfloat16)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"{model_size/1000**2:.1f}M parameters\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ff03a-f2ce-41c5-b06e-a0874f211d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655ead1-1924-4d48-9e20-f02aa57a3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "#num_train_epochs=1,\n",
    "#resume_from_checkpoint=True,\n",
    "#gradient_checkpointing=True,\n",
    "#torch_compile=True,\n",
    "#logging_dir = out_dir/run\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"model_{my_model_type}\",\n",
    "\n",
    "    resume_from_checkpoint=True,\n",
    "\n",
    "    max_steps=5000,\n",
    "    warmup_steps=300,\n",
    "    eval_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=5000,\n",
    "    \n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.1,\n",
    "    adam_beta2=0.95,\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=32,\n",
    "    \n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    #gradient_checkpointing=True,\n",
    "    #activation_checkpointing=True,\n",
    "    torch_compile=True,\n",
    "    \n",
    "    report_to=\"tensorboard\",\n",
    "    logging_steps=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae57f0-08fd-4354-9984-595cfea2ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args, \n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af376ca-1e86-410d-8fb0-08f749a29034",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34d665-525d-4525-a05d-d40a7f8bbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ./model_llama_60m/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
